[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Weekly Learning Diary",
    "section": "",
    "text": "Welcome\nThis is a weekly learning diary to document coursework from the module CASA0023 Remotely Sensing Cities and Environments (T2 2023).\nUse the navigation bar to switch between chapters/weeks. There is also a Glossary page which collects and explains key remote sensing terms.\n[Add Intro on me]\nThis site is built by Joe. To see more about my work visit https://github.com/joepost.\nThis site is built using Quarto. To learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Blair, B. O., and M. F. Baumgardner. 1977. “Detection of the\nGreen and Brown Wave in Hardwood Canopy\nCovers Using Multidate, Multispectral Data from\nLANDSAT-11.” Agronomy Journal 69 (5):\n808–11. https://doi.org/10.2134/agronj1977.00021962006900050019x.\n\n\nCohen, W. B., and S. N. Goward. 2004. “Landsat’s Role in\nEcological Applications of Remote Sensing.” BioScience\n54 (6): 535–45. https://doi.org/10.1641/0006-3568(2004)054[0535:LRIEAO]2.0.CO;2.\n\n\nCrist, Eric P., and Richard C. Cicone. 1984. “A Physically-Based\nTransformation of Thematic Mapper Data—The TM\nTasseled Cap.” IEEE Transactions on Geoscience and\nRemote Sensing, no. 3: 256–63.\n\n\nDymond, Caren C., David J. Mladenoff, and Volker C. Radeloff. 2002.\n“Phenological Differences in Tasseled Cap Indices\nImprove Deciduous Forest Classification.” Remote Sensing of\nEnvironment 80 (3): 460–72.\n\n\nFassnacht, F. E., H. Latifi, K. Stereńczak, A. Modzelewska, M. Lefsky,\nL. T. Waser, C. Straub, and A. Ghosh. 2016. “Review of Studies on\nTree Species Classification from Remotely Sensed Data.”\nRemote Sensing of Environment 186: 64–87. https://doi.org/10.1016/j.rse.2016.08.013.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David\nThau, and Rebecca Moore. 2017. “Google Earth Engine:\nPlanetary-scale Geospatial Analysis for\nEveryone.” Remote Sensing of Environment, Big\nRemotely Sensed Data: Tools, applications and experiences,\n202 (December): 18–27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nHarvey, Fiona. 2021. “Athens Appoints Chief Heat Officer to Combat\nClimate Crisis.” The Guardian: Environment, July 23,\n2021. https://www.theguardian.com/environment/2021/jul/23/athens-appoints-chief-heat-officer-combat-climate-crisis.\n\n\nHorowitz, Jason. 2021. “Athens Is Only Getting\nHotter. Its New ‘Chief Heat\nOfficer’ Hopes to Cool It\nDown.” The New York Times: World, August 21,\n2021. https://www.nytimes.com/2021/08/21/world/europe/athens-is-only-getting-hotter-its-new-chief-heat-officer-hopes-to-cool-it-down.html.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing: A\nRemote Sensing Perspective. 4th ed. Prentice-Hall Inc.\n\n\nJohnson, D. P., A. Stanforth, V. Lulla, and G. Luber. 2012.\n“Developing an Applied Extreme Heat Vulnerability Index Utilizing\nSocioeconomic and Environmental Data.” Applied Geography\n35 (1-2): 23–31. https://doi.org/10.1016/j.apgeog.2012.04.006.\n\n\nKauth, Richard J., and G. S. Thomas. 1976. “The Tasselled Cap–a\nGraphic Description of the Spectral-Temporal Development of Agricultural\nCrops as Seen by Landsat.” In LARS\nSymposia, 159.\n\n\nRidd, M. K., and J. Liu. 1998. “A Comparison of Four Algorithms\nfor Change Detection in an Urban Environment.” Remote Sensing\nof Environment 63 (2): 95–100. https://doi.org/10.1016/S0034-4257(97)00112-0.\n\n\nSturrock, Hugh JW, Justin M. Cohen, Petr Keil, Andrew J. Tatem, Arnaud\nLe Menach, Nyasatu E. Ntshalintshali, Michelle S. Hsiang, and Roland D.\nGosling. 2014. “Fine-Scale Malaria Risk Mapping from Routine\nAggregated Case Data.” Malaria Journal 13 (1, 1): 1–9.\nhttps://doi.org/10.1186/1475-2875-13-421.\n\n\nSulova, Andrea, and Jamal Jokar Arsanjani. 2021. “Exploratory\nAnalysis of Driving Force of\nWildfires in Australia: An\nApplication of Machine Learning Within Google\nEarth Engine.” Remote Sensing 13 (1, 1): 10. https://doi.org/10.3390/rs13010010.\n\n\nTempfli, K., G. C. Huurneman, L. L. F. Janssen, and N. Kerle, eds. 2009.\nPrinciples of Remote Sensing : An Introductory Textbook.\nInternational Institute for Geo-Information Science and Earth\nObservation. https://research.utwente.nl/en/publications/principles-of-remote-sensing-an-introductory-textbook-4.\n\n\nTomlinson, C. J., L. Chapman, J. E. Thornes, and C. J. Baker. 2011.\n“Including the Urban Heat Island in Spatial Heat Health Risk\nAssessment Strategies: A Case Study for\nBirmingham, UK.” International\nJournal of Health Geographics 10. https://doi.org/10.1186/1476-072X-10-42.\n\n\nUnited Nations. 2022. “The Sustainable Development Goals\nReport 2022.” New York, NY: United\nNations. https://unstats.un.org/sdgs/report/2022/.\n\n\nUnited Nations Environment Program. 2021. “Beating the\nHeat: A Sustainable Cooling Handbook for\nCities.” Nairobi, Kenya:\nUNEP. http://www.unep.org/resources/report/beating-heat-sustainable-cooling-handbook-cities.\n\n\nWu, C., and A. T. Murray. 2003. “Estimating Impervious Surface\nDistribution by Spectral Mixture Analysis.” Remote Sensing of\nEnvironment 84 (4): 493–505. https://doi.org/10.1016/S0034-4257(02)00136-0.\n\n\nYuan, F., and M. E. Bauer. 2007. “Comparison of Impervious Surface\nArea and Normalized Difference Vegetation Index as Indicators of Surface\nUrban Heat Island Effects in Landsat Imagery.”\nRemote Sensing of Environment 106 (3): 375–86. https://doi.org/10.1016/j.rse.2006.09.003.\n\n\nZha, Y., J. Gao, and S. Ni. 2003. “Use of Normalized Difference\nBuilt-up Index in Automatically Mapping Urban Areas from TM\nImagery.” International Journal of Remote Sensing 24\n(3): 583–94. https://doi.org/10.1080/01431160304987."
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Introduction to Remote Sensing",
    "section": "",
    "text": "The topic of this week’s learning diary are an introduction to remote sensing, the principles of EMR, types of satellites and sensors, and sources of remote sensing data.\nThe practical session for this week introduced methods for extracting open access remote sensing data, including Sentinel data from the ESA’s Copernicus Open Access Hub and Landsat data from the USGS EarthExplorer."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Remote Sensor: The OCO-2",
    "section": "",
    "text": "To view this presentation full-screen, click here."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Image Corrections",
    "section": "",
    "text": "This section will cover corrections of remote sensing data, to account for atmospheric noise, shadow and distortion, and other processes affecting the raw output."
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nThere is a wide variety of types of remote sensors and remote sensing data, and an equally wide variation in application. Some examples include:\n\n\n\nEarth Observation Data Source\nOperator\nApplication Examples\n\n\n\n\nDynamic World\nGoogle Earth Engine (GEE) app, developed jointly by Google and the World Resources Institute.\nReal-time, high resolution (~10m) land cover\n\n\nLandsat\nNASA/USGS\n\nUrban/green space coverage\nUrban heat island\nIllegal logging\nNatural disasters (bushfire, flooding)\n\n\n\nSentinel\nESA (European Space Agency)\n\nPollution\nIllegal logging\nUrban heat island\nOceanic monitoring\nNatural disasters\n\n\n\n\n\n1.1.1 What is remote sensing?\nAt its simplest, remote sensing is the collection of data or information about an entity (such as an object or geographic area) from a distance. In practice, this usually refers to the use of airborne or orbiting sensors designed to measure certain properties of electromagnetic energy exiting an object/area (Jensen 2015).\n\n\n\n\n\n\nNote\n\n\n\nThe Electromagnetic Spectrum (EMS)\nElectromagnetic radiation is the flow of energy travelling at the speed of light. It encompasses a spectrum that includes visible light, radio waves, and x-rays, among others, which have different scales of wave frequency and intensity (amplitude).\nRemote sensors are often designed to measure a specific band of the electromagnetic spectrum, such as the visible light spectrum or near infrared (NIR).\nDifferent materials (physical, biological, chemical) reflect and absorb energy at different points along the spectrum; therefore different sections of the EMS are relevant for different applications. For example, analysing NIR radiation can help to identify vegetation in earth observation data, and even the health or ‘stress’ state of the plant (Tempfli et al. 2009), in ways that just analysing the visible spectrum is unable to.\n\n\n\nWavelengths along the electromagnetic spectrum. Source: (Tempfli et al. 2009)\n\n\n\n\nRadiation (usually from the sun) is reflected by an object and this reflected energy is then detected by a remote sensor. However, there are several processes that affect and transform this energy due to interactions with the Earth’s surface and the atmosphere before the energy reaches the sensor. In many cases, scattering of radiation in the atmosphere requires image correction before the data can be used. This process is covered in Section 3.1.\n\n\n\nSurface and atmospheric interactions of radiation. Source: [@tempfliPrinciplesRemoteSensing2009]\n\n\n\n\n1.1.2 Types of remote sensing\n\n\n\n\n\n\n\n\nType\nDetails\nExamples\n\n\n\n\nPassive\nUse energy that is available in the environment - in most cases, this is reflected energy from the sun.\nMost common form of remote sensor, includes Landsat, SENTINEL\n\n\nActive\nEmit an energy source and then detect the reflection of this energy from the remote surface.\nRADAR, LiDAR, SAR\n\n\n\nIn addition to the two types of remote sensing data, the data itself can be broken up into four metadata attributes:\n\nSpatial Resolution: the size of a raster cell (pixel) projected onto the ground. For example, a single pixel might represent a 10m x 10m area, or a 100m x 100m area.\nSpectral Resolution: the EMR bands that the data is recorded in (e.g. the red, green and blue bands of the visible light spectrum). Hyperspectral data refers to remote sensors that record an almost continuous observation across a range of the EMR spectrum, as opposed to discrete layers for a certain band region.\nRadiometric Resolution: the range of possible values for a raster cell, expressed in units of bits (e.g. 8-bit, 12-bit). Describes the ability of the sensor to differentiate between small differences in energy.\nTemporal Resolution: the frequency at which the data is collected (e.g. every few hours, every 16 days, yearly)"
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nThis week’s practical task involved downloading Sentinel data and Landsat data to investigate using QGIS and SNAP software, including the application of a tasseled-cap transformation. The tasseled-cap transformation emerged from the development of spectral vegetation indices (SVIs) using multispectral data from the original Landsat mission, launched in 1972 (Cohen and Goward 2004). SVIs are a key tool in ecological and agricultural monitoring using remote sensing data, having the benefit of greater sensitivity to vegetation phenology (i.e. the periodic changes in plant growth across seasons) than analysis of individual spectral bands (Blair and Baumgardner 1977).\nThe tasseled-cap transformation is an extension of SVIs, first developed by Kauth and Thomas (1976), that is intended to capture spectral characteristics of soil, as opposed to just vegetation. It has been iteratively improved over time following improvements in the quality and availability of Landsat data, and is now commonly derived using three indices: Brightness, Greenness and Wetness (Cohen and Goward 2004; Crist and Cicone 1984).\n\n\n\nAn example of the tasseled-cap transformation indices. Source: [@cohenLandsatRoleEcological2004]\n\n\nTasseled-cap transformation continues to be used in ecological applications, such as classifying forest structure (e.g., Dymond, Mladenoff, and Radeloff 2002) or tree species (Fassnacht et al. 2016), but has also been applied in urban land classification research - for example, in analysis of urban green space and soil characteristics (Ridd and Liu 1998)."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nIn this introduction week, the topics that stood out to me were the ingenuity of the technical aspects, bridging the gap between the physics of electromagnetic radiation and applying this knowledge to produce very powerful and informative datasets. These aspects include the mechanics behind a sensor’s spectral resolution, the translation of images into distributions of pixel values, and the additional considerations of using an active sensor.\n\nSpectral ResolutionPixel DistributionsActive Sensors\n\n\nWhen reading about a sensor, the band range will often be specified - e.g., a sensor may be described to observe the area of the electromagnetic spectrum between 525 - 605 nm (nanometres being a measure of the wavelength). However (and this is quite intuitive when you stop to think about it), the sensor does not actually have such a discrete cut-off at these wavelengths. Detectors are actually sensitive to a region of the EMS, where the maximum sensitivity is at the middle spot of this region, with sensitivity declining as it moves away from this point. The stated range given for sensors uses the Full Width at Half Maximum (FWHM) criteria, which is the range of wavelengths detected at 50% or greater intensity, as shown in the figure below, from (Jensen 2015).\n\n\n\nDefining spectral resolution using the Full Width at Half Maximum Criteria\n\n\n\n\nI found conceptualising a remote sensing image as a simple distribution of pixel values a very powerful way to think about how the data can be analysed, understood, and transformed. A practical example of this is the use of histograms to ‘stretch’ the colours in an image, to improve differentiation and visual interpretation. The histogram of pixel values will commonly follow an approximately normal distribution, but a colour gradient will run linearly from the minimum to the maximum value of the dataset, which will result in a much ‘shallower’ gradient. Different methods can be used to rectify this, such as stretching or clipping to min/max.\n\n\nJensen et al. (Jensen 2015) warn that “powerful active remote sensor systems that emit their own electromagnetic radiation (e.g., LiDAR, RADAR, SONAR) can be intrusive and affect the phenomenon being investigated. Additional research is required to determine how intrusive these active sensors can be.” (p.8). I would be interested to investigate further what kind of research has been done in this area, or what kind of impacts active sensing methods are hypothesised to have. In which situation would the process of using an active sensor disturb the process being observed?\n\n\n\n\n\n\n\nBlair, B. O., and M. F. Baumgardner. 1977. “Detection of the Green and Brown Wave in Hardwood Canopy Covers Using Multidate, Multispectral Data from LANDSAT-11.” Agronomy Journal 69 (5): 808–11. https://doi.org/10.2134/agronj1977.00021962006900050019x.\n\n\nCohen, W. B., and S. N. Goward. 2004. “Landsat’s Role in Ecological Applications of Remote Sensing.” BioScience 54 (6): 535–45. https://doi.org/10.1641/0006-3568(2004)054[0535:LRIEAO]2.0.CO;2.\n\n\nCrist, Eric P., and Richard C. Cicone. 1984. “A Physically-Based Transformation of Thematic Mapper Data—The TM Tasseled Cap.” IEEE Transactions on Geoscience and Remote Sensing, no. 3: 256–63.\n\n\nDymond, Caren C., David J. Mladenoff, and Volker C. Radeloff. 2002. “Phenological Differences in Tasseled Cap Indices Improve Deciduous Forest Classification.” Remote Sensing of Environment 80 (3): 460–72.\n\n\nFassnacht, F. E., H. Latifi, K. Stereńczak, A. Modzelewska, M. Lefsky, L. T. Waser, C. Straub, and A. Ghosh. 2016. “Review of Studies on Tree Species Classification from Remotely Sensed Data.” Remote Sensing of Environment 186: 64–87. https://doi.org/10.1016/j.rse.2016.08.013.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing: A Remote Sensing Perspective. 4th ed. Prentice-Hall Inc.\n\n\nKauth, Richard J., and G. S. Thomas. 1976. “The Tasselled Cap–a Graphic Description of the Spectral-Temporal Development of Agricultural Crops as Seen by Landsat.” In LARS Symposia, 159.\n\n\nRidd, M. K., and J. Liu. 1998. “A Comparison of Four Algorithms for Change Detection in an Urban Environment.” Remote Sensing of Environment 63 (2): 95–100. https://doi.org/10.1016/S0034-4257(97)00112-0.\n\n\nTempfli, K., G. C. Huurneman, L. L. F. Janssen, and N. Kerle, eds. 2009. Principles of Remote Sensing : An Introductory Textbook. International Institute for Geo-Information Science and Earth Observation. https://research.utwente.nl/en/publications/principles-of-remote-sensing-an-introductory-textbook-4."
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  Case Study: Athens",
    "section": "",
    "text": "How can remote sensing data be applied to help achieve policy goals?\n\n\nAthens Heatwave Action Plan launched in 2016\nAppointed a Chief Heat Officer in 2021, tasked with reducing the impacts of extreme heat waves in the Greek capital, and improving resilience to the urban heat island (UHI) effect\nPolicy goals: increasing green areas, expanding the use of cool materials, increasing shade options, and promoting “cooling routes” in parts of the city where the urban heat island effect is more intense.\nUnder a strategic partnership between the city and the National Observatory of Athens, a digital heatwave warning mechanism created to alert residents via personal computers or smartphones. The mechanism provides the current temperature in the user’s location, whether or not they are at risk depending on their age and medical condition, as well as how to reach a cooling spot in case they are at risk\n\nStatements from CHO:\n\n“The first and most important goal is to make the city greener and to create an infrastructure that would bring more nature and water into the city … We need to increase the number of parks in Athens that already provide shelter to vulnerable residents. Parks can help a great deal to bring down temperatures in the city; they absorb CO2 emission and retain water, they increase biodiversity, create oxygen, clean the air from microparticles so they also help to fight pollution.” Eurocities News\n\n“The second solution will be carried out in the short-term. The plan is to give wider access to air conditioning to the most vulnerable groups and help them to lower temperatures in their homes during heatwaves. Air conditioning will play a role in this case. We know it increases outdoor heat and CO2 emissions, but it will be necessary to protect people from getting sick or dying.”\n“Together with meteorologists and climate scientists, we are considering naming heatwaves and categorising them like hurricanes. This will make events more prominent in people’s minds, turning weather phenomena into an entity. People are able to think of an event more clearly if they can call it by a name and media can more easily communicate it to their audiences. Categorising heatwaves will help authorities to set up risk management protocols.”"
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "4  Case Study: Athens",
    "section": "4.2 Application",
    "text": "4.2 Application\nPotential applications for remote sensing data have been broken down into the three main strategies outlined by Myrivili above: (1) Increase urban greening, (2) provide relief to the most vulnerable, and (3) improve risk communication.\n\n4.2.1 Increase urban greening\nUsing remote sensing data to monitor vegetation and land cover in urban areas is well-established, and there is a depth of scientific literature to demonstrate this (for example, Zha, Gao, and Ni 2003; Wu and Murray 2003). Through automated classification of surface land use/land cover (LULC) using remote sensing, the city of Athens could directly measure progress towards the goal of 30% land cover being vegetation or permeable surfaces by 2030. Yuan et al. (2007) demonstrate that freely available Landsat imagery would generally provide a sufficient data source for this task.\n\n\n4.2.2 Provide relief to the most vulnerable\nIncluding a dimension of vulnerability into risk measurement suggests the need for data fusion - combining remote sensing data of LULC and surface temperature with spatial socioeconomic data, collected through a population census, government administrative datasets, or research surveys. Johnson et al. (2012) showed that calculating an extreme heat vulnerability index (EHVI) consisting of census data and remotely sensed imagery was able to explain nearly 80% of the variance in heat-health vulnerability when applied to a heatwave event in Chicago, and accurately captured a trend of higher death rates in high risk zones and lower death rates in low risk zones. A similar approach has been applied by researchers in Birmingham, UK (Tomlinson et al. 2011) to identify the spatial distribution of heat vulnerability.\n\n\n\nFlowchart of incorporating remote sensing hazard data with sociodemographic vulnerability, from Tomlinson et al. (2011)\n\n\n\n\n\nVulnerability risk map of Birmingham, from Tomlinson et al. (2011)\n\n\nIn Athens, these approaches could be used to provide an evidence basis for policy intervention, identifying areas of greatest need for rapid intervention such as installing air conditioning or creating public “cool zones”, and providing subsidies for energy use to address pockets of energy poverty.\n\n\n4.2.3 Improve risk communication\nAs mentioned in the quote and video above (The Policy Context), the City of Athens has proposed naming and categorising heatwave events, in an attempt to improve public awareness of severity and the associated risk. The city has already put this proposal into action, working with the National Observatory of Athens to incorporate meteorological remote sensing data into a digital warning mechanism, that will warn user’s smartphones on heatwaves, factors of risk, and nearby cool zones (Horowitz 2021)."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Case Study: Athens",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nAthens provides an interesting case study, as a city that has already taken demonstrable steps towards heat mitigation and a very public awareness campaign through the posting of the Chief Heat Officer. It combines both the high-level rhetoric of sustainability and resilience, which have near universal adoption through initiatives such as the UN Sustainable Development Goals, with concrete policy actions, which are much rarer. In particular, the existing partnership with the National Observatory of Athens highlights that the metropolitan government are already bridging the gap between research and action.\n\n\n\n\nHarvey, Fiona. 2021. “Athens Appoints Chief Heat Officer to Combat Climate Crisis.” The Guardian: Environment, July 23, 2021. https://www.theguardian.com/environment/2021/jul/23/athens-appoints-chief-heat-officer-combat-climate-crisis.\n\n\nHorowitz, Jason. 2021. “Athens Is Only Getting Hotter. Its New ‘Chief Heat Officer’ Hopes to Cool It Down.” The New York Times: World, August 21, 2021. https://www.nytimes.com/2021/08/21/world/europe/athens-is-only-getting-hotter-its-new-chief-heat-officer-hopes-to-cool-it-down.html.\n\n\nJohnson, D. P., A. Stanforth, V. Lulla, and G. Luber. 2012. “Developing an Applied Extreme Heat Vulnerability Index Utilizing Socioeconomic and Environmental Data.” Applied Geography 35 (1-2): 23–31. https://doi.org/10.1016/j.apgeog.2012.04.006.\n\n\nTomlinson, C. J., L. Chapman, J. E. Thornes, and C. J. Baker. 2011. “Including the Urban Heat Island in Spatial Heat Health Risk Assessment Strategies: A Case Study for Birmingham, UK.” International Journal of Health Geographics 10. https://doi.org/10.1186/1476-072X-10-42.\n\n\nUnited Nations. 2022. “The Sustainable Development Goals Report 2022.” New York, NY: United Nations. https://unstats.un.org/sdgs/report/2022/.\n\n\nUnited Nations Environment Program. Mon, 11/08/2021 - 14:57. “Beating the Heat: A Sustainable Cooling Handbook for Cities.” Nairobi, Kenya: UNEP. http://www.unep.org/resources/report/beating-heat-sustainable-cooling-handbook-cities.\n\n\nWu, C., and A. T. Murray. 2003. “Estimating Impervious Surface Distribution by Spectral Mixture Analysis.” Remote Sensing of Environment 84 (4): 493–505. https://doi.org/10.1016/S0034-4257(02)00136-0.\n\n\nYuan, F., and M. E. Bauer. 2007. “Comparison of Impervious Surface Area and Normalized Difference Vegetation Index as Indicators of Surface Urban Heat Island Effects in Landsat Imagery.” Remote Sensing of Environment 106 (3): 375–86. https://doi.org/10.1016/j.rse.2006.09.003.\n\n\nZha, Y., J. Gao, and S. Ni. 2003. “Use of Normalized Difference Built-up Index in Automatically Mapping Urban Areas from TM Imagery.” International Journal of Remote Sensing 24 (3): 583–94. https://doi.org/10.1080/01431160304987."
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "3  Week 3",
    "section": "3.2 Application",
    "text": "3.2 Application\nText"
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Week 3",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nText"
  },
  {
    "objectID": "week3.html#sec-week3application",
    "href": "week3.html#sec-week3application",
    "title": "3  Image Corrections",
    "section": "3.2 Application",
    "text": "3.2 Application\nText"
  },
  {
    "objectID": "week3.html#sec-week3reflection",
    "href": "week3.html#sec-week3reflection",
    "title": "3  Image Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nText\nTry and summarise in what situations corrections would be needed (e.g. will I always be able to download pre-processed data anyway? When would one need to proceed with corrections calculations)\nExplore some methods for mosaicking?\nReflection: discuss how different correction methods can be applied, and how this can affect the interpretation and outcome (reference findings from Detoni et al. 2023); links back to the idea of remote sensing as science + art"
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "4  Case Study: Athens",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nHow can remote sensing data be applied to help achieve policy goals?\nCities across the globe are introducing policies and targets to address the growing challenges of climate change, disaster resilience, and sustainability. This case study explores the approach of the Greek capital, Athens, and how a policy to address the Urban Heat Island (UHI) effect and protect residents from deadly heatwaves could incorporate remote sensing data.\n\n4.1.1 The Policy Context\nIn 2021, the City of Athens appointed a Chief Heat Officer, Elena Myrivili - a European first, and the second globally following a similar appointment in Miami, Florida, in the same year (Harvey 2021). Although a temporary position, Myrivili’s role as Chief Heat Officer was designed to raise the profile of heat as the city’s deadliest climate event, and to coordinate a metropolitan-scale response to building heat resilience - through strategies such as increased green space and urban canopy, adjusting the design of roads and buildings, and improving systems to warn residents during particularly dangerous heatwaves.\nWatch the video below to see Myrivili outline the impacts heat has had on her city, and the broad strategies to combat this.\n\nPolicy goals outlined by the Chief Heat Officer:\n\nIncrease urban greening\n\n\n“The first and most important goal is to make the city greener and to create an infrastructure that would bring more nature and water into the city … We need to increase the number of parks in Athens that already provide shelter to vulnerable residents. Parks can help a great deal to bring down temperatures in the city; they absorb CO2 emission and retain water, they increase biodiversity, create oxygen, clean the air from microparticles so they also help to fight pollution.”\n\n\nProvide immediate relief to the most vulnerable\n\n\n“The second solution will be carried out in the short-term. The plan is to give wider access to air conditioning to the most vulnerable groups and help them to lower temperatures in their homes during heatwaves. Air conditioning will play a role in this case. We know it increases outdoor heat and CO2 emissions, but it will be necessary to protect people from getting sick or dying.”\n\n\nRaise awareness and improve risk communication\n\n\n“We are considering naming heatwaves and categorising them like hurricanes. This will make events more prominent in people’s minds, turning weather phenomena into an entity. People are able to think of an event more clearly if they can call it by a name and media can more easily communicate it to their audiences. Categorising heatwaves will help authorities to set up risk management protocols.”\n\nSource: (Horowitz 2021)\nConcurrently, the City of Athens has also developed a Climate Change Action Plan which feeds into much of the work of the Chief Heat Officer, and includes goals to transition 30% of the city surface to vegetation and/or permeable surfaces by 2030, and in the same time frame ensure that 70% of the city’s populations has access to green space within a 15 minute walk.\nThese goals are reflected in both the regional and global context. Athens is prominently involved in European Union initiatives for urban resilience as a signatory to the European Commission’s Covenant of Mayors for Climate and Energy. In a broader sense, addressing climate change as an impact on health and livelihoods aligns with the United Nation’s Sustainable Development Goals, a high-level framework for directing global patterns of development and resilience (United Nations 2022), and the UN Environment Program’s (UNEP) Beat the Heat report, a sustainable cooling handbook for cities (United Nations Environment Program Mon, 11/08/2021 - 14:57)."
  },
  {
    "objectID": "week3.html#sec-week3summary",
    "href": "week3.html#sec-week3summary",
    "title": "3  Image Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThis section will cover corrections applied to remote sensing data, to account for atmospheric noise, shadow and distortion, and other processes affecting the raw output. In practice, corrections will most often be dealt with by the image provider - where data is made available ‘analysis ready’. Search source metadata for details on which corrections have been applied, and the calculations used.\n\n3.1.1 Types of Correction\n\n\n\n\n\n\n\n\nType\nDescription\nExamples\n\n\n\n\nGeometric Correction (includes Orthorectification, or Topographic Correction) *CHECK THIS\nAccounts for differences in sensor view angles. Corrections will use methods such as ground control points, where known points are identified in both images. See figure below.\nMaking the images taken straight down (“nadir”) comparable to images from off-centre (“off-nadir”)\n\n\nAtmospheric Correction\nAccounts for the ‘haze’ caused by atmospheric scattering and absorption.\nUsing Dark Object Subtraction (DOS) to quantify the difference between surface reflectance and top-of-atmosphere (TOA) reflectance.\n\n\nResampling\nAccounts for difference in spatial resolution of raster images. Resampling is used to calculate values for ‘lower’ resolution pixels calculated from the component higher resolution pixels.\nUsed to resample Landsat bands taken at 10m resolution into lower resolution 20m pixels, to allow band math with other bands recorded at 20m resolution. [SPECIFY THE BANDS AT 20; FROM PRAC 1]\n\n\nRadiometric Calibration\nAccounts for the conversion of unitless data collected by the sensor (a ‘Digital Number’) to a value indicating the spectral radiance.\nThe transition from Digital Number to Radiance to Reflectance represents different values corresponding to increasing levels of correction/processing.\n\n\nPoint Spread Functions\nAccounts for the spread of reflectance values that contribute to a single pixel. The centre of a pixel will have the greatest influence on the observed reflectance; point spread functions calculate the influence of pixel sections as distance increases from the centre.\n\n\n\n\nUsing ground control points in geometric correction:\n[INSERT IMAGE FROM NOTION]"
  },
  {
    "objectID": "week5.html#sec-week5summary",
    "href": "week5.html#sec-week5summary",
    "title": "5  Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nWhat is Google Earth Engine (GEE)?\nEarth Engine is a cloud-based application designed for the analysis and exploration of remote sensing data. It provides access to powerful supercomputing resources and an extensive database of freely available remote sensing data, from a variety of sources and sensors. The data in Earth Engine is preprocessed and analysis-ready, and the catalogue is continuously updated with data becoming available on average within 24 hours of acquisition (Gorelick et al. 2017).\nHow does it work?\nAnalysis is divided between a client side - the Earth Engine browser interface - and the server side, where the data is stored and the processing is performed.\nDue to the huge volume of data that can be involved in Earth Engine calculations and visualisations, the system also uses different methods to reduce data load/computing time:\n\nPyramid ScalingLazy ComputationDistributed Computing\n\n\nIn Earth Engine, the spatial resolution is determined by the output, not the input. The system stores a ‘pyramid’ of progressively reduced resolution tiles, which adjust depending on the scale of the user’s view. The smaller (reduced resolution) layers of the pyramid are calculated through a down-sampling method, such as the mean for numeric data, or the mode for classification data.\n\n\n‘Lazy’ computation refers to the process of only computing the data that are necessary, such as that in the user’s current view (if using an interactive display). The window’s zoom level and bounds will dynamically control the projection and resolution of the computed data.\n\n\nThe Earth Engine code library provides a suite of inbuilt functions that are designed to maximise performance on the cloud-based computing system. Methods such as parallelisation and distributed computing break down larger jobs to be run across many smaller machines, allowing faster times to produce client output.\n\n\n\nSource: Gorelick et al. (2017)\nWhat data can I find?\nEarth Engine holds a broad data catalogue, which can be accessed here: https://developers.google.com/earth-engine/datasets.\nGorelick et al. (2017) also provide a useful summary table of key satellites and datasets."
  },
  {
    "objectID": "week5.html#sec-week5application",
    "href": "week5.html#sec-week5application",
    "title": "5  Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nBuilding a remote sensing machine learning pipeline using Earth Engine\nSulova and Jokar Arsanjani (2021) incorporated Earth Engine data into a machine learning pipeline, for the analysis of drivers of wildfire in Australia. This study is interesting because it outlines the full workflow of an open source remote sensing analysis, from the collection and processing of freely available data in Earth Engine to then become an input into a series of machine learning models (random forest, naive bayes, and a classification and regression tree) to identify the most effective. The output of the study is an automated workflow for developing large, labelled training datasets using Earth Engine to be applied in supervised machine learning.\nIn the flowchart below, Earth Engine is used for the extraction and analysis of Sentinel-2, FIRMS, DEM, NDVI and other satellite image collections, in the pre-processing stage.\n\n\n\n\n\nFiner scale malaria mapping in low transmission settings\nSturrock et al. (2014) have used remote sensing data from Earth Engine in conjunction with routine malaria case data from health facilities to map malaria risk in Eswatini (Swaziland). The researchers used a suite of remotely sensed ecological/environmental covariates, including enhanced vegetation index (EVI), normalised difference water index (NDWI), and normalised difference vegetation index (NDVI), captured by MODIS and sourced from Earth Engine. All covariates were resampled to a 1km resolution and then fed into a hierarchical modelling framework.\nThe study is intended as a proof-of-concept for implementing the methodology in diverse settings. Utilising Earth Engine for the remote sensing aspect means the method can be freely and relatively easily replicated, especially in potentially resource-limited settings."
  },
  {
    "objectID": "week5.html#sec-week5reflection",
    "href": "week5.html#sec-week5reflection",
    "title": "5  Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nOne of the key valuable lessons I found this week was an explanation of the Red-Blue-Green colour channels, and how they apply in Earth Engine (and remote sensing imagery in general), from the Howarth (2021) reading. When displaying an image digitally, the three colour channels are combined in an additive colour system (based in light, as opposed to subtractive colour composition, which is the result of mixing pigments or dyes - the distinction between these was an initial point of confusion for me).\nBands, which contain the data from a remote sensor at a specific spectral range, can be combined in the colour channels in any order. The order specifies which colour channel is used to display the digital number (DN) of the pixel. If the DN in the first band is higher compared with the other two bands, the pixel will appear reddish. I found this explanation made it much clearer for me when interpreting composite images. The diagram below breaks down how colours on a screen correlate to certain band value combinations (Howarth 2021).\n\n\n\nSource: Howarth, 2021\n\n\n\n\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. 2017. “Google Earth Engine: Planetary-scale Geospatial Analysis for Everyone.” Remote Sensing of Environment, Big Remotely Sensed Data: Tools, applications and experiences, 202 (December): 18–27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nHowarth, Jeff. 2021. “Exploring Images.” In Cloud-Based Remote Sensing with Google Earth Engine, edited by Jeffrey A. Cardille, Nick Clinton, Morgan A. Crowley, and David Saah. https://www.eefabook.org/.\n\n\nSturrock, Hugh JW, Justin M. Cohen, Petr Keil, Andrew J. Tatem, Arnaud Le Menach, Nyasatu E. Ntshalintshali, Michelle S. Hsiang, and Roland D. Gosling. 2014. “Fine-Scale Malaria Risk Mapping from Routine Aggregated Case Data.” Malaria Journal 13 (1, 1): 1–9. https://doi.org/10.1186/1475-2875-13-421.\n\n\nSulova, Andrea, and Jamal Jokar Arsanjani. 2021. “Exploratory Analysis of Driving Force of Wildfires in Australia: An Application of Machine Learning Within Google Earth Engine.” Remote Sensing 13 (1, 1): 10. https://doi.org/10.3390/rs13010010."
  },
  {
    "objectID": "week6.html#sec-week6summary",
    "href": "week6.html#sec-week6summary",
    "title": "6  Classification I",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nWhat is image classification?\nThe purpose of classification is to transform a raster of remote sensing spectral data into a meaningful set of categories, to aid interpretation and usability. A common example is the development of land use/land cover (LULC) maps, which distinguish between features such as water, vegetation, bare soil, and built environment.\nHow does it work?\nImage classification methods can be broken down into three broad types, summarised in the table below.\n\n\n\n\n\n\n\n\nMethod\nExample\nDetails\n\n\n\n\nUnsupervised (pixel-based)\nK-means clustering; ISODATA\nAlgorithm groups pixels into a specified number of clusters, which must then be manually classified based on their features.\n\n\nSupervised (pixel-based)\nMaximum likelihood, Minimum distance, Principal components analysis (PCA), Support vector machine (SVM)\nInvolves training and testing sets. Train the model on data labelled with desired categories, and then apply the model to a new image/dataset to classify.\n\n\nObject identification\nObject based image analysis (OBIA)\nAs opposed to pixel-based, seeks to combine groups of pixels into discrete objects. My involve input statistics such as shape, texture, context, and spectral signature. At high spatial resolutions, OBIA generally outperforms pixel-based classification, as it accounts for both spectral and contextual information.\n\n\n\nIt is also possible to define between a hard or fuzzy logic for per-pixel classification. Hard classification produces singular, discrete values for each pixel (e.g. a pixel that contains a combination of forest and water will be classified solely as one or the other, depending on the method). Fuzzy classification is an attempt to better represent the heterogeneous nature of the real-world being observed. Instead of being assigned to a single discrete class, each pixel is given an estimate of the proportion of each land-cover type found within it (e.g. 20% water, 70% forest, 10% scrub/grassland) (Jensen 2015 , Ch.9). The concept of fuzzy classification and sub-pixel analysis is discussed further in Chapter 7.\nGive us an example\nThe Iterative Self-Organising Data Analysis Technique (ISODATA) is an extension of k-means clustering analysis, a form of unsupervised classification. Key modifications include combining clusters that are too ‘close together’ in the dimensional feature space, and applying rules for splitting single clusters into two.\n\nParameters in an ISODATA classification algorithm. Source: Jensen (2015)\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\n\\(C_{max}\\)\nMaximum number of clusters\n\n\n\\(T\\)\nMaximum % pixels whose class values can remain the same between iterations\n\n\n\\(M\\)\nMaximum number of times the algorithm iterates through classifying pixels and recalculating cluster mean vectors.\n\n\nMin. members\nMinimum % of members in a cluster. Clusters below this threshold are deleted and the members assigned to alternative clusters.\n\n\nMin. distance\nMinimum separation distance between cluster means. Clusters with a separation distance below this threshold are merged.\n\n\n\\(\\sigma_{max}\\)\nDetermines when a cluster is split into two."
  },
  {
    "objectID": "week6.html#sec-week6application",
    "href": "week6.html#sec-week6application",
    "title": "6  Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\nSupervised classification for disaster risk assessment\nA key component of disaster management and resilience is identifying areas at greatest risk of damage - where risk is a function of both hazard (the likelihood of disaster affecting the area) and vulnerability (the loss or damage an area would suffer in the event of disaster). Remote sensing data combined with classification tools can be used to develop risk maps in diverse settings. For example, support vector machines (SVMs), have been applied in flood settings in Malaysia by Tehrany et al. (2014) and Mojadaddi et al. (2017).\nIn each case, a set of parameters are standardised and form the inputs for the SVM, and the output being a ‘flooded’ or ‘non-flooded’ label for each pixel/observation. The SVM ‘hyperplane’ is then optimised to find the greatest separation amongst the data while minimising the number of misclassification errors (Pal and Mather 2005). From this, a hazard map can be built that estimates the probability of flood in a certain pixel given the value of the input parameters. The final output of each study is a map where each pixel or raster cell has a single value indicating the risk indice.\n\n\n\nExample of a flood risk map developed using SVM supervised classification. Source: Mojadaddi et al. 2017."
  },
  {
    "objectID": "week6.html#sec-week6reflection",
    "href": "week6.html#sec-week6reflection",
    "title": "6  Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nI found support vector machines the heftiest conceptual challenge for this week. At first sight, terminology such as hyperplanes and support vectors is intimidating to absorb within a fast-paced lecture, but I found the resources such as Srivastava’s Support Vector Machines article on Medium, and Pal and Mather’s article Support vector machines for classification in remote sensing (2005) useful to flesh out the concept and break down the complexity. Further, seeing how the method can be applied in context (as described above) gave me a better sense of the rationale behind the method and how it adapts from other machine learning classification methods.\n\n\n\n\nJensen, John R. 2015. Introductory Digital Image Processing: A Remote Sensing Perspective. 4th ed. Prentice-Hall Inc.\n\n\nMojaddadi, H., B. Pradhan, H. Nampak, N. Ahmad, and A. H. B. Ghazali. 2017. “Ensemble Machine-Learning-Based Geospatial Approach for Flood Risk Assessment Using Multi-Sensor Remote-Sensing Data and GIS.” Geomatics, Natural Hazards and Risk 8 (2): 1080–1102. https://doi.org/10.1080/19475705.2017.1294113.\n\n\nPal, M., and P. M. Mather. 2005. “Support Vector Machines for Classification in Remote Sensing.” International Journal of Remote Sensing 26 (5): 1007–11. https://doi.org/10.1080/01431160512331314083.\n\n\nTehrany, M. S., B. Pradhan, and M. N. Jebur. 2014. “Flood Susceptibility Mapping Using a Novel Ensemble Weights-of-Evidence and Support Vector Machine Models in GIS.” Journal of Hydrology 512: 332–43. https://doi.org/10.1016/j.jhydrol.2014.03.008."
  },
  {
    "objectID": "week7.html#sec-week7summary",
    "href": "week7.html#sec-week7summary",
    "title": "7  Classification II",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nRecap: what was covered in Classification I (Week 6)?\nWeek 6 covers the basics of classification techniques in remote sensing, including distinguishing between supervised and unsupervised methods, and an example of different methods (ISODATA, SVM) and their application.\nWhat is covered in Classification II?\nThis diary entry covers object based analysis and sub-pixel analysis, spatial cross-validation, and measures of accuracy for classification models.\n\nObject Based Image Analysis (OBIA)Sub-pixel AnalysisSpatial Cross-ValidationAccuracy Assessment\n\n\nTrains a model to classify images based on ‘objects’ - segments of pixels that have been grouped together as single entity. This compares with pixel-based analysis where each pixel is classified in isolation. There are two steps to OBIA:\n\nSegmentation: grouping the pixels together into discrete objects which should be defined by similar shape and spectral characteristics. Benz, Baatz and Schreier (2001) developed an early approach to segmentation specifically for remote sensing data, which aggregates similar pixels into segments while keeping the measured heterogeneity below a specified threshold. Heterogeneity is measured as a combination of both spectral and spatial characteristics - where spatial is further broken down into measures of smoothness and compactness.\nClassification: classify the segmented objects, using the same methods as would be used in a pixel-based analysis.\n\nOBIA has advantages over pixel-based analysis in that the model is not restricted to spectral information; rather, the model also takes the pixel’s context into account (i.e. through measures of shape).\n\n\nAlso known as Spectral Mixture Analysis (SMA) or Linear spectral unmixing.\nEstimates the fractions of certain land cover classes that make up a single pixel. Attempts to account for the fact that land cover (in reality) does not have discrete boundaries. Calculating sub-pixel values utilises spectrally pure endmembers. These are the spectral characteristics of land cover known to be ‘pure’, or a single class - by contrast, most of the spectral reflectance observed by a sensor will be a function of the radiation/reflectance from a variety of endmember materials within the ground sampling distance (Jensen 2015).\nThe figure below illustrates how land cover classes may form fractions of a single pixel, and the conceptual basis behind sub-pixel analysis (Machado and Small 2013).\n\n\n\nSource: Machado & Small (2013)\n\n\nUseful toolkit: MESMA from the R library RStoolbox\n\n\nSpatial cross-validation (CV) is designed to account for the effects of spatial autocorrelation in classification models. It is an extension of traditional (non-spatial) CV models, but instead of randomly sampling the split between test/train data, the data is split spatially in clusters (to minimise the effects of testing points being adjacent to training points, and thus invalidating the assumption of independence).\nAn additional alternative is to use a distance buffer around testing points, to prevent any nearby points being included in the training set. This distance can be fixed arbitrarily, or through using Moran’s I to calculate distance at which spatial autocorrelation effects become insignificant (Karasiak et al. 2022).\n\n\n\nTypes of spatial and non-spatial cross-validation. LOO = ‘Leave One Out’; SLOO = ‘Spatial Leave One Out’. Source: Karasiak et al. (2022)\n\n\n\n\nLike in any machine learning model, the performance of a remote sensing classification needs to be assessed to understand effectiveness and comparability to other models. In remote sensing there are a number of performance metrics, which can be represented in a confusion matrix.\n\n\n\nSource: Barsi et al. (2018)\n\n\nThe acronyms in the matrix above are as follows (Barsi et al. 2018):\n\n\n\n\n\n\n\nAcronym\nDefinition\n\n\n\n\nTP\nTrue Positive\n\n\nFP\nFalse Positive (alt: type I error)\n\n\nTN\nTrue Negative\n\n\nFN\nFalse Negative (alt: type II error)\n\n\nUA\nUser’s Accuracy (alt: Precision, Positive Predictive Value)\n\n\nCE\nComission Error (alt: false discovery rate)\n\n\nNPV\nNegative Prediction Value\n\n\nFOR\nFalse Omission Rate\n\n\nPA\nProducer’s Accuracy (alt: recall, true positive rate, sensitivity)\n\n\nTNR\nTrue Negative Rate\n\n\nOE\nOmission Error (alt: false negative rate)\n\n\nFPR\nFalse Positive Rate\n\n\nOA\nOverall Accuracy\n\n\n\nOf the measures above, the User’s Accuracy, Producer’s Accuracy and Overall Accuracy are the most common reported performance metrics.\nA multi-class confusion matrix can also be represented:\n\n\n\nSource: Barsi et al. (2018)"
  },
  {
    "objectID": "week7.html#sec-week7application",
    "href": "week7.html#sec-week7application",
    "title": "7  Classification II",
    "section": "7.2 Application",
    "text": "7.2 Application\nThe development of classification models in remote sensing is very much an evolving process, as new methods are developed to optimise predictive capability whilst accounting for spatial dependency (autocorrelation). A (conceptually) simple model that accounts for spatial dependence is leave one out cross validation (LOO-CV), developed by Canovas-Garcia et al. (2017). The authors also developed an R package, SDRF, to work alongside the randomForest package and explicitly incorporate spatial splitting.\nAs part of this study, the authors assessed the performance results of random forest models accounting for spatial dependence compared with non-spatial counterparts. In this case, a confusion matrix comparing multiple models would become cumbersome, and the authors instead innovatively represented two common metrics, omission error and commission error, using a sequence of pyramid graphs, which provides a quick way to compare results across models and case study areas.\n\n\n\nError pyramid comparing random forest classification models. Source: Canovas-Garcia et al. (2017)."
  },
  {
    "objectID": "week7.html#sec-week7reflection",
    "href": "week7.html#sec-week7reflection",
    "title": "7  Classification II",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nThis week, I was interested in a case study presented by Karasiak et al. (Karasiak et al. 2022), and as reported by Inglada (Inglada 2018), that highlights the importance of context and domain knowledge when evaluating classification models, outside of purely using performance metrics. In the TiSeLaC (Time Series Land Cover Classification Challenge) machine learning challenge, participants were tasked with the goal of producing a classification model with performance evaluated using F-scores (a machine learning metric that combines precision/UA and recall/PA scores of a model). One of the winning entrants scored an exceptionally high F-score of between 90 - 98%. Upon further investigation, Inglada found that the model was built using spatial nearest-neighbour classification, with the feature input being the pixel coordinates - i.e., no spectral data was used in the prediction.\nThese results confirm that (1) spatial autocorrelation was evident in the input data, as would be expected for remote sensing imagery, and (2) neighbouring pixels were present in the training and test sets, meaning that the test set was not independent from the training data (Inglada 2018). The takeaway from this is that focusing purely on metric optimisation, without considering the process or conceptual underpinning of the model, can easily lead to misleading results. I find that this lesson is a useful reminder of the importance of a multidisciplinary understanding, and that a machine learning specialist (even if they have a much deeper understanding of machine learning processes) may not be better suited to an applied geospatial task.\n\n\n\n\nBarsi, Á., Zs. Kugler, I. László, Gy. Szabó, and H. M. Abdulmutalib. 2018. “Accuracy Dimensions in Remote Sensing.” The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences XLII-3 (April): 61–67. https://doi.org/10.5194/isprs-archives-XLII-3-61-2018.\n\n\nBenz, U., M. Baatz, and G. Schreier. 2001. “OSCAR-object Oriented Segmentation and Classification of Advanced Radar Allow Automated Information Extraction.” In IGARSS 2001. Scanning the Present and Resolving the Future. Proceedings. IEEE 2001 International Geoscience and Remote Sensing Symposium (Cat. No.01CH37217), 4:1913–1915 vol.4. https://doi.org/10.1109/IGARSS.2001.977114.\n\n\nCánovas-García, Fulgencio, Francisco Alonso-Sarría, Francisco Gomariz-Castillo, and Fernando Oñate-Valdivieso. 2017. “Modification of the Random Forest Algorithm to Avoid Statistical Dependence Problems When Classifying Remote Sensing Imagery.” Computers & Geosciences 103 (June): 1–11. https://doi.org/10.1016/j.cageo.2017.02.012.\n\n\nInglada, Jordi. 2018. “Machine learning for land cover map production – Follow-up on the TiSeLaC challenge.” 2018. https://labo.obs-mip.fr/multitemp/machine-learning-for-land-cover-map-production-follow-up-on-the-tiselac-challenge/.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing: A Remote Sensing Perspective. 4th ed. Prentice-Hall Inc.\n\n\nKarasiak, N., J.-F. Dejoux, C. Monteil, and D. Sheeren. 2022. “Spatial Dependence Between Training and Test Sets: Another Pitfall of Classification Accuracy Assessment in Remote Sensing.” Machine Learning 111 (7): 2715–40. https://doi.org/10.1007/s10994-021-05972-1.\n\n\nMachado, Reinaldo P. P., and Christopher Small. 2013. “Identifying Multi-Decadal Changes of the Sao Paulo Urban Agglomeration with Mixed Remote Sensing Techniques: Spectral Mixture Analysis and Night Lights.” EARSeL eProceedings 12 (2): 101."
  },
  {
    "objectID": "week8.html#sec-week8summary",
    "href": "week8.html#sec-week8summary",
    "title": "8  Urban Heat Island",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nWhat is the Urban Heat Island effect?\nThe Urban Heat Island (UHI) phenomenon is where urban areas have comparatively higher temperatures (atmospheric and surface) compared with surrounding rural areas. Caused by comparatively lower vegetation, an increase in dark and impervious surfaces, and density of energy/electricity expenditure (e.g. transport, air conditioning). The urban morphology can intensify the UHI effect; for example, Debbage and Shepherd (2015) found in a study of 50 US cities that spatial contiguity (e.g. unbroken developed land) increased the magnitude of the UHI effect, whether in densely populated or sprawling cities.\nWhat is the impact?\nThere is an extensive body of literature on the diverse impacts of UHI. Roxon et al. (2020) quantified the added financial cost and CO2 emissions due to increased energy demand in US cities exposed to UHI, especially in summer months. Interestingly, the authors also estimated the benefits of UHI in some colder climate cities, by reducing energy demand for heating during colder months. The UHI also exacerbates the effect of heat waves and a warming climate, leading to increased morbidity and mortality for urban residents (Margolis 2014; Bi et al. 2011; Mücke and Litvinovitch 2020).\nWhat can be done?\nThe UHI effect features prominently in policy goals and urban discourse around the globe, as demonstrated by high-level reports such as the United Nation’s ‘Beat the Heat’ report (United Nations Environment Program 2021), billed as a “sustainable cooling handbook for cities”. In terms of local mitigation approaches, there are diverse examples, such as the development of “green corridors” of trees in Medellin, Colombia, traffic reduction and increased vegetation through Barcelona’s ‘superblocks’, or coordinated metropolitan wide responses as in the case of Athens’ Chief Heat Officer (see Week 4 for further details)."
  },
  {
    "objectID": "week8.html#sec-week8application",
    "href": "week8.html#sec-week8application",
    "title": "8  Urban Heat Island",
    "section": "8.2 Application",
    "text": "8.2 Application\nAlthough the negative impacts of extreme heat and the UHI effect in cities are huge and demand significant attention and action, I found the study by Roxon, Ulm and Pellenq (2020) which examined the potential benefits of UHI in cold climates particularly interesting. The importance of these findings are stark - in the US, the heating and cooling of buildings contributes up to 20-25% of total energy consumption, which corresponds to a significant fraction of the country’s carbon emissions. The question here is, can the UHI effect be used to an advantage to reduce energy consumption in cold climate cities, and by extension, is the implementation of UHI mitigation strategies in cold climate cities likely to increase energy demand and associated emissions?\nBased on their findings, the authors go so far as to suggest that cold climate cities (which they classify as covering most of the US) should actively design cities around maximising the UHI effect, such as through encouraging a high-density, gridded urban morphology. However, there are a number of clear limitations - the study is not remote-sensing based, and does not incorporate spatial data below state-level aggregates (i.e., even individual cities are not included in the units of analysis). All results are therefore also limited to the statewide level.\nAlthough I found some remote sensing articles with a focus on the UHI effect in cool-climate cities (e.g. 2015)"
  },
  {
    "objectID": "week8.html#sec-week8reflection",
    "href": "week8.html#sec-week8reflection",
    "title": "8  Urban Heat Island",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nIn Week 4, I covered the work of the Athens Chief Heat Officer, a project supported by the Rockefeller foundation’s Resilient Cities Network. Melbourne, Australia, has recently joined this movement with the appointment of two Chief Heat Officers in October 2022, who will coordinate the city’s response to increasing temperatures and mitigating the UHI effect (Walls 2022), with the city’s aim being “to cool Melbourne by four degrees, to improve liveability, resilience, and community health” (City of Melbourne 2022).\n\n\n\nPromotional announcement of the appointment of 2 Chief Heat Officers by the City of Melbourne. Source: Arsht-Rock Resilience Centre.\n\n\nIt’s interesting to see how this movement has gained traction globally, and whether time will show that municipal governments implementing this approach produce more effective heat mitigation outcomes. In most cases, strategies to reduce urban heat (such as greening, or changing materials used in buildings and infrastructure) require long term planning and long periods to take effect. In time, a research project that considers the policy history and pathways of these cities in conjunction with remotely sensed time series temperature data, could provide an interesting comparison and evaluation into this strategy, and determine whether Chief Heat Officers become ubiquitous across municipal governments in future.\n\n\n\n\nBi, Peng, Susan Williams, Margaret Loughnan, Glenis Lloyd, Alana Hansen, Tord Kjellstrom, Keith Dear, and Arthur Saniotis. 2011. “The Effects of Extreme Heat on Human Mortality and Morbidity in Australia: Implications for Public Health.” Asia Pacific Journal of Public Health 23 (March): 27S–36S. https://doi.org/10.1177/1010539510391644.\n\n\nCity of Melbourne. 2022. “Heat Safe City.” 2022. https://participate.melbourne.vic.gov.au/heat-safe-city/heat-safe-city-overview.\n\n\nDebbage, Neil, and J. Marshall Shepherd. 2015. “The Urban Heat Island Effect and City Contiguity.” Computers, Environment and Urban Systems 54 (November): 181–94. https://doi.org/10.1016/j.compenvurbsys.2015.08.002.\n\n\nMargolis, Helene G. 2014. “Heat Waves and Rising Temperatures: Human Health Impacts and the Determinants of Vulnerability.” In Global Climate Change and Public Health, edited by Kent E. Pinkerton and William N. Rom, 85–120. Respiratory Medicine. New York, NY: Springer. https://doi.org/10.1007/978-1-4614-8417-2_6.\n\n\nMücke, Hans-Guido, and Jutta Maria Litvinovitch. 2020. “Heat Extremes, Public Health Impacts, and Adaptation Policy in Germany.” International Journal of Environmental Research and Public Health 17 (21, 21): 7862. https://doi.org/10.3390/ijerph17217862.\n\n\nRoxon, J., F. -J. Ulm, and R. J. -M. Pellenq. 2020. “Urban Heat Island Impact on State Residential Energy Cost and CO2 Emissions in the United States.” Urban Climate 31 (March): 100546. https://doi.org/10.1016/j.uclim.2019.100546.\n\n\nUnited Nations Environment Program. 2021. “Beating the Heat: A Sustainable Cooling Handbook for Cities.” Nairobi, Kenya: UNEP. http://www.unep.org/resources/report/beating-heat-sustainable-cooling-handbook-cities.\n\n\nWalls, Wendy. 2022. “Melbourne Now Has Chief Heat Officers. Here’s Why We Need Them and What They Can Do.” The Conversation. October 16, 2022. http://theconversation.com/melbourne-now-has-chief-heat-officers-heres-why-we-need-them-and-what-they-can-do-192248.\n\n\nWang, Yupeng, Umberto Berardi, and Hashem Akbari. 2015. “The Urban Heat Island Effect in the City of Toronto.” Procedia Engineering, Defining the future of sustainability and resilience in design, engineering and construction, 118 (January): 137–44. https://doi.org/10.1016/j.proeng.2015.08.412."
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "Term \n    Definition \n    Reference Week \n  \n \n\n  \n    Amplitude \n    The height of the peak of an electromagnetic wave. \n    1 \n  \n  \n    Atmospheric transmission \n    The transmission of a particular EMR wavelength through Earth’s atmosphere (i.e. how much is not absorbed by gases) \n    1 \n  \n  \n    Bidirectional Reflectance Distribution Function (BRDF) \n    Driven by changes in the viewpoint (the sensor) and the illumination source (i.e. the sun), and the way energy is reflected from the earth’s surface. \n    1 \n  \n  \n    Bottom of atmosphere (BOA) reflectance \n    Synonymous with Surface reflectance (see entry). Compare with Top of atmosphere (TOA) reflectance. \n    2 \n  \n  \n    Data fusion \n    The combination of data from multiple sources with different spatial and spectral resolutions, such as SAR and passive sensor data. \n    3 \n  \n  \n    Electromagnetic radiation (EMR) \n    Waves of an electromagnetic field, travel through space and carry radiant energy. \n    1 \n  \n  \n    Emittance \n    Energy leaving a surface per unit area per unit time (from EMR). \n    1 \n  \n  \n    Exitance \n    Energy leaving a surface per unit area (from EMR). \n    1 \n  \n  \n    Feature (GEE) \n    Google Earth Engine term for vector data \n    5 \n  \n  \n    Feature Space \n    A scatterplot of two bands from a spectral image \n    5 \n  \n  \n    FeatureCollection (GEE) \n    Google Earth Engine term for a stack of vector data (lots of polygons) \n    5 \n  \n  \n    Geostationary orbit \n    Satellite holds the same position over Earth’s surface (less common for EO sensors) \n    2 \n  \n  \n    Geosynchronous orbit \n    Satellite matches the Earth’s rotation \n    2 \n  \n  \n    Ground resolution cell \n    The size of the pixel from a remote sensing image projected onto the ground. Relates to the Ground Sampling Distance. \n    1 \n  \n  \n    Ground sampling distance \n    The distance between the centres of two adjacent resolution cells of the same channel. Ideally, the Ground Resolution Cell and Ground Sampling Distance should be equal (Tempfli et al. 2009, p.138). \n    1 \n  \n  \n    Image (GEE) \n    Google Earth Engine term for raster data \n    5 \n  \n  \n    ImageCollection (GEE) \n    Google Earth Engine term for a stack of raster data \n    5 \n  \n  \n    LULC \n    Land Use Land Cover. Generally refers to the classification of human activities and natural elements on the landscape based on emote sensing data. \n    6 \n  \n  \n    Mean Radiant Temperature \n    A calculation of the temperature as it is experienced by humans, as opposed to land surface temperature (LST). Incorporates elements such as shading and building morphology. \n    8 \n  \n  \n    Mie scattering \n    Atmospheric scattering where particles are the same size compared to wavelength. \n    1 \n  \n  \n    Nadir \n    The location on Earth directly below a satellite sensor \n    2 \n  \n  \n    Non-selective scattering \n    Atmospheric scattering where particles are much larger than the wavelength. \n    1 \n  \n  \n    Orthorectification \n    The process of correcting remote sensing images to remove sensor, satellite/aircraft motion and terrain-related geometric distortions from raw imagery. \n    3 \n  \n  \n    Pan sharpening \n    Short for panchromatic sharpening. Combines high-resolution detail from a panchromatic band with lower resolution colour detail from other bands, to produce a single ‘sharper’ colour image. \n    3 \n  \n  \n    Planimetric \n    In remote sensing, refers to a flat image (showing no relief or angle) \n    3 \n  \n  \n    Polar orbit \n    Describes the orbit of remote sensing satellites that travel roughly over the Earth’s poles (north to south), as opposed to east to west. \n    2 \n  \n  \n    Polarisation \n    Refers to the direction of wave vibration in relation to the direction of propagation. The degree of polarisation in reflected light is affected by a variety of factors including the illumination, surface roughness, color, and sensing geometry. \n    1 \n  \n  \n    Pushbroom scanning \n    Sensors that use a line of detectors arranged perpendicular to the flight direction of the spacecraft. As the spacecraft flies forward, the image is collected one line at a time, with all the pixels in that line being collected simultaneously. Compare with Whisk scanning. \n    2 \n  \n  \n    Radiant energy \n    Energy carried by EMR waves. \n    1 \n  \n  \n    Radiant flux \n    Radiant energy (EMR) per unit of time. \n    1 \n  \n  \n    Rayleigh scattering \n    Atmospheric scattering where the particles are very small compared with the wavelength. \n    1 \n  \n  \n    Solar azimuth \n    The angle of the direction of the sun measured clockwise north from the horizon. \n    1 \n  \n  \n    Solar flux \n    Energy from the sun per unit area per unit time (from EMR). \n    1 \n  \n  \n    Solar irradiance \n    Energy from the sun per unit area (from EMR). Irradiance is energy at any angle (in comparison with radiance which has a specific angle). \n    1 \n  \n  \n    Spectrally Pure Endmembers \n    Spectral characteristics of land cover that contains only a single class/is unmixed. For example, a pixel that is known to contain only bare soil and no vegetation (e.g. through field validation). Endmembers can then be used to estimate sub-pixel proportions of land cover classes in the rest of an image. \n    7 \n  \n  \n    Sun-synchronous orbit \n    A type of polar orbit of satellites, where the satellite is is synchronised to always be in the same ‘fixed’ position relative to the sun. This means that the satellite always visits the same spot at the same local time – for example, passing the city of Paris every day at noon exactly. \n    2 \n  \n  \n    Support Vector Machine (SVM) \n    A statistical tool for binary classification, which attempts to find the optimal ‘separation’ between two groups of data. \n    6 \n  \n  \n    Surface reflectance \n    The amount of light reflected by the surface of the Earth; the fraction of solar radiation reflected from Earth’s surface to the remote sensor. It is a ratio of surface radiance to surface irradiance, with values between 0 and 1. Compare with Top of atmosphere (TOA) reflectance. \n    1 \n  \n  \n    Synthetic Aperture Radar (SAR) \n    An active sensor that collects at longer wavelengths than optical (passive) sensors. Used to detect surface through cloud cover. \n    1 \n  \n  \n    Top of atmosphere (TOA) reflectance \n    The reflectance measured by a remote sensor, which includes contributions/distortions from clouds and atmospheric scattering. Compare with surface reflectance. \n    1 \n  \n  \n    Vicarious calibration \n    Using handheld spectroradiometers to validate remotely sensed data \n    6 \n  \n  \n    Wavelength \n    The distance between successive peaks of an electromagnetic wave \n    1 \n  \n  \n    Whisk scanning \n    Sensors that use a mirror to reflect light onto a single detector. The mirror moves back and forth, to collect measurements from one pixel in he image at a time. Compare with Pushbroom scanning. \n    2 \n  \n  \n    Zenith \n    The opposite of nadir; can be used to describe the location of the sun \n    2"
  }
]